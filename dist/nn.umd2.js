(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory();
	else if(typeof define === 'function' && define.amd)
		define([], factory);
	else if(typeof exports === 'object')
		exports["NN"] = factory();
	else
		root["NN"] = factory();
})(window, function() {
return /******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./src/index.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./src/_.js":
/*!******************!*\
  !*** ./src/_.js ***!
  \******************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("const _ = function() {}\n\n/**\n* Clamping (coined by Christian Echevarria) is used to reffer\n* to bounding JavaScript values to real numbers when they run\n* off towards `Infinity`.\n*\n* @param {number} x\n*\n* @returns {number}\n*\n* @example\n* _.clamp(Infinity) // => 1.7976931348623157e+308\n* _.clamp(-infinity) // => -1.7976931348623157e+308\n* _.clamp(0) // => 0\n* _.clamp(3.14159) // => 3.14159\n*/\n_.clamp = function(x) {\n  return x === Infinity ? Number.MAX_VALUE : x === -Infinity ? -Number.MAX_VALUE : x;\n}\n\nmodule.exports = _;\n\n\n//# sourceURL=webpack://NN/./src/_.js?");

/***/ }),

/***/ "./src/connection.js":
/*!***************************!*\
  !*** ./src/connection.js ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/**\n * Connections help:\n *     * a) control the flow information inside of a neural network\n *     * b) describe the shape of a neural network\n *     * c) ease the use of Evolutionary Algoriths\n *\n * To facilitate the use of Evolutionary Algoriths, Connections are given Unique\n * _Temporal-Structural IDs_ using the [Cantor Pairing Algorithm](https://en.wikipedia.org/wiki/Pairing_function).\n *\n * _Temporal-Structural IDs_: are not only a method of uniquely identifying a\n * connection, they also allow us to identify a) where in the network the\n * connection exists (i.e. between what neurons), and b) when it was\n * \"created-ish\".\n *\n * Connection IDs created using the _Cantor Pairing Algorithm_ enable stronger\n * algorithms, i.e. NEAT/HyperNEAT, to create networks of arbitrary\n * sizes/shapes.\n *\n * @constructs Connection\n *\n * @prop {string} id Unique connection ID\n * @prop {Neuron|Group} a Side \"A\" of connection(s)\n * @prop {Neuron|Group} b Side \"B\" of connection(s)\n * @prop {number|number[]} [weight] Weight of connection(s)\n *\n * @param {Neuron|Group} a Neuron(s) on one edge of the connection\n * @param {Neuron|Group} b Neruon(s) on another edge of the connection\n * @param {number|number[]} [weight] Weight of connection(s)\n * @param {Object} [options]\n *\n * @example\n * const connection = new Connection(neuron, other) // Connection { a: neuron, b: other }\n *\n * const connection = new Connection(neuron, other, 0.3) // Connection { a: neuron, b: other, weight: 0.3 }\n */\nfunction Connection(from, to, weight, options) {\n  this.id = Connection.uid(from.id, to.id);\n  this.from = from;\n  this.to = to;\n  this.weight = weight == undefined ? Math.random() * 2 - 1 : weight;\n\n\n  //================================================\n  // UTILITY FUNCTIONS =============================\n  //================================================\n  this.toJSON = function() {\n    return {\n      id: this.id,\n      from: this.from.id,\n      to: this.to.id,\n      weight: this.weight\n    }\n  }\n\n  //================================================\n  // EXPERIMENTAL ==================================\n  //================================================\n  // this.queue = {\n  //   forward: [],\n  //   backward: []\n  // }\n  // this.stream = {\n  //   forward: undefined,\n  //   backward: undefined\n  // }\n\n  // this.push = function(payload, forward=true) {\n  //   if(forward) this.queue.forward.unshift(payload);\n  //   else this.queue.backward.unshift(payload)\n  // }\n  // this.pull = function(forward=false) {\n  //   if(forward) return this.queue.forward.shift(payload);\n  //   else return this.queue.backward.shift(payload);\n  // }\n  //================================================\n  // END EXPERIMENTAL ==============================\n  //================================================\n}\n\n/**\n* Creates a unique structural ID for connection between two neurons using the\n* [Cantor Pairing Algorithm](https://en.wikipedia.org/wiki/Pairing_function).\n*\n* The _Cantor Pairing Algorithm_ us to a) mathematically, map any two\n* non-negative integers to a unique positive integer - it even is sensetive to\n* order (i.e. `Connection.uid([2,3]) !== Connection.uid([3,2])`), and b) \"AI-ly\"\n* it allows to keep track of unique structural connections across time as a\n* neural network mutates (i.e. changes \"shape\").\n*\n* @param {number} fromID - ID of _source_ neuron\n* @param {number} toID - ID of _destination_ neuron\n*\n* @returns {number} A unique integer ID created using the [Cantor Pairing Algorithm](https://en.wikipedia.org/wiki/Pairing_function)\n*/\nConnection.uid = function(fromID, toID) {\n  return 0.5 * (fromID + toID) * (fromID + toID + 1) + toID;\n}\n\nmodule.exports = Connection;\n\n\n//# sourceURL=webpack://NN/./src/connection.js?");

/***/ }),

/***/ "./src/group.js":
/*!**********************!*\
  !*** ./src/group.js ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// const uid = require(\"cuid\");\nconst Neuron = __webpack_require__(/*! ./neuron */ \"./src/neuron.js\");\nconst Connection = __webpack_require__(/*! ./connection */ \"./src/connection.js\");\n\n/**\n * A `Group` is an abstraction of `Neuron` and a tool for creating and manipulating a group of neurons - with `Group` we can create neural network layers and and build networks faster than neuron-by-neuron construction.\n *\n * @constructs Group\n *\n * @param {number} [size]\n * @param {number} [bias]\n *\n * @prop {string} id\n * @prop {Neuron[]} neurons\n */\nfunction Group(size, bias) {\n  // this.id = uid();\n\n  this.neurons = size == undefined ? [] : Array.from({ length: size }, function() {\n    return new Neuron(bias);\n  });\n\n  //================================================\n  // CORE FUNCTIONS ================================\n  //================================================\n  /**\n   * @param {Group} target\n   * @param {number[]} [weights]\n   *\n   * @example\n   * //===============================================\n   * // 2x2 (No Weights) =============================\n   * //===============================================\n   * const { Group } = require(\"@liquidcarrot/nn\")\n   *\n   * const group = new Group(2);\n   * const other = new Group(2);\n   *\n   * group.connect(other);\n   *\n   * //===============================================\n   * // 2x2 (Weights) =============================\n   * //===============================================\n   * const { Group } = require(\"@liquidcarrot/nn\")\n   *\n   * const group = new Group(2);\n   * const other = new Group(2);\n   *\n   * // group[0] -- weights[0] --> other[0]\n   * // group[0] -- weights[1] --> other[1]\n   * // group[1] -- weights[2] --> other[0]\n   * // group[1] -- weights[3] --> other[1]\n   * group.connect(other, [0.1, 0.2, 0.3, 0.4]);\n   */\n  this.connect = function(target, weights) {\n    const self = this;\n\n    this.neurons.forEach(function(neuron, a) {\n      target.neurons.forEach(function(other, b) {\n        if(weights) neuron.connect(other, weights[self.neurons.length * a + b]);\n        else neuron.connect(other);\n      })\n    })\n  }\n\n  /**\n   * @param {number[]} [inputs]\n   *\n   * @returns {number[]}\n   *\n   * @example\n   * //===============================================\n   * // One Group (No Hidden Layers) =================\n   * //===============================================\n   * const { Group } = require(\"@liquidcarrot/nn\")\n   *\n   * const group = new Group(2);\n   *\n   * neuron.activate([0, 0]); // [0, 0]\n   *\n   * //===============================================\n   * // Three Groups (Hidden Layers) =================\n   * //===============================================\n   * const { Group } = require(\"@liquidcarrot/nn\")\n   *\n   * const input = new Group(2); // Input Neuron (Layer)\n   * const hidden = new Group(2,0.1); // Hidden Neuron (Layer)\n   * const output = new Group(2,0.15); // Output Neuron (Layer)\n   *\n   * input.connect(hidden, [0.2,0.25,0.3,0.35]); // Connects input layer to hidden layer\n   * hidden.connect(output, [0.4,0.45,0.5,0.55]); // Connects hidden layer to output layer\n   *\n   * input.activate([0,0]); // [0,0]\n   * hidden.activate(); // [0.###, 0.###]\n   * output.activate(); // [0.###, 0.###]\n   *\n   */\n  this.activate = function(inputs) {\n    return this.neurons.map(function(neuron, index) {\n      if(inputs) return neuron.activate(inputs[index]);\n      else return neuron.activate();\n    })\n  }\n\n  /**\n   * @param {number[]} [targets]\n   * @param {number} [rate=0.3]\n   *\n   * @returns {number[]}\n   *\n   * @example\n   * //===============================================\n   * // One Group (No Hidden Layers) =================\n   * //===============================================\n   * const { Group } = require(\"@liquidcarrot/nn\")\n   *\n   * const group = new Group(2);\n   *\n   * neuron.activate([0, 0]); // [0, 0]\n   * neuron.propagate([0, 1]); // [0, -1]\n   *\n   * //===============================================\n   * // Three Groups (Hidden Layers) =================\n   * //===============================================\n   * const { Group } = require(\"@liquidcarrot/nn\")\n   *\n   * const input = new Group(2); // Input Neuron (Layer)\n   * const hidden = new Group(2,0.1); // Hidden Neuron (Layer)\n   * const output = new Group(2,0.15); // Output Neuron (Layer)\n   *\n   * input.connect(hidden, [0.2,0.25,0.3,0.35]); // Connects input layer to hidden layer\n   * hidden.connect(output, [0.4,0.45,0.5,0.55]); // Connects hidden layer to output layer\n   *\n   * input.activate([0,0]); // [0,0]\n   * hidden.activate(); // [0.###, 0.###]\n   * output.activate(); // [0.###, 0.###]\n   *\n   * output.propagate([0, 1]); //  [0, -1]\n   * hidden.propagate(); // [0.###, 0.###]\n   * input.propagate(); // [0.###, 0.###]\n   */\n  this.propagate = function(targets, rate=0.3) {\n    return this.neurons.map(function(neuron, index) {\n      if(targets) return neuron.propagate(targets[index]);\n      else return neuron.propagate();\n    })\n  }\n  //================================================\n  // END CORE FUNCTIONS ============================\n  //================================================\n\n  //================================================\n  // UTILITY FUNCTIONS =============================\n  //================================================\n\n  //Code here...\n\n  //================================================\n  // END UTILITY FUNCTIONS =========================\n  //================================================\n}\n\nGroup.connect = function(from, to) {\n  const connections = [];\n  for(let f = 0; f < from.length; f++) {\n    for(let t = 0; t < to.length; t++) {\n      connections.push(new Connection(from[f], to[t]));\n    }\n  }\n  return connections;\n}\n\nmodule.exports = Group;\n\n\n//# sourceURL=webpack://NN/./src/group.js?");

/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("const NN = {\n  _: __webpack_require__(/*! ./_ */ \"./src/_.js\"),\n  Connection: __webpack_require__(/*! ./connection */ \"./src/connection.js\"),\n  Neuron: __webpack_require__(/*! ./neuron */ \"./src/neuron.js\"),\n  Group: __webpack_require__(/*! ./group */ \"./src/group.js\"),\n  Network: __webpack_require__(/*! ./network */ \"./src/network.js\"),\n  // Bot: require(\"./bot\")\n}\n\nmodule.exports = NN;\n\n\n//# sourceURL=webpack://NN/./src/index.js?");

/***/ }),

/***/ "./src/network.js":
/*!************************!*\
  !*** ./src/network.js ***!
  \************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// const uid = require(\"cuid\");\nconst Connection = __webpack_require__(/*! ./connection */ \"./src/connection.js\");\nconst Neuron = __webpack_require__(/*! ./neuron */ \"./src/neuron.js\");\nconst Group = __webpack_require__(/*! ./group */ \"./src/group.js\");\n// const vis = require(\"vis-network\");\n\n\n\n/**\n * Each `Network` is a collective of neurons functioning as an individual and indepent agent (brain).\n *\n * @constructs Network\n *\n * @param {number[]} sizes\n * @param {number[]} [biases]\n * @param {Array.<number[]>} [weights]\n *\n * @prop {string} id\n * @prop {Group[]} groups\n *\n * @example\n * const { Network } = require(\"@liquid-carrot/nn\");\n *\n * const network = new Network([2,2,1]);\n *\n * network.activate([0,1]);\n * network.propagate([1]);\n */\nfunction Network(network, biases, weights) {\n  let self = this;\n\n  this.id = Network.uid();\n  this.neurons = [];\n  this.connections = [];\n\n  //================================================\n  // CORE FUNCTIONS ================================\n  //================================================\n  /**\n   * Activates network\n   *\n   * @param {number[]} inputs\n   *\n   * @returns {number[]}\n   */\n  this.activate = function(inputs) {\n    return Math.random() * 2 - 1;\n\n    // const outputs = this.groups.map(function(group, index) {\n    //   if(index === 0) return group.activate(inputs);\n    //   else return group.activate();\n    // })\n    //\n    // return outputs[outputs.length - 1];\n  }\n\n  /**\n   * Calculates error & updates network weights\n   *\n   * @param {number[]} targets\n   *\n   * @returns {number} Returns Mean-Squared Error (MSE)\n   */\n  this.propagate= function(targets) {\n    return Math.random() * 2 - 1;\n\n    // // MSE Cost\n    // const error = this.groups[this.groups.length - 1].neurons.map(function(neuron, index) {\n    //   return 0.5 * Math.pow(targets[index] - neuron.output, 2);\n    // }).reduce((a,b) => a + b);\n    //\n    // // Propagate error & update weights\n    // this.groups.reverse().forEach(function(group, index) {\n    //   if(index === 0) group.propagate(targets);\n    //   else return group.propagate();\n    // }); this.groups.reverse();\n    //\n    // return error;\n  }\n  //================================================\n  // END CORE FUNCTIONS ============================\n  //================================================\n\n  //================================================\n  // UTILITY FUNCTIONS =============================\n  //================================================\n\n  /**\n  * Returns a JSON representation of the network\n  *\n  * @returns {Object}\n  */\n  this.toJSON = function() {\n    const neurons = this.neurons.flat(Infinity).map(function(neuron) {\n      return neuron.toJSON();\n    });\n    const connections = this.connections.flat(Infinity).map(function(connection) {\n      return connection.toJSON();\n    });\n    return { neurons, connections }\n  }\n\n  /**\n  * **BROWSER ONLY**\n  *\n  * Creates a graph of the network using [`vis-network`](https://www.npmjs.com/package/vis-network) on the given DOMElement\n  * or DOMElement ID.\n  *\n  * @param {string|DOMElement} element - DOMElement, or ID, where graph will ported into\n  * @param {Object} [options] - `vis-network` options - [learn more](https://visjs.github.io/vis-network/docs/network/#options)\n  */\n  this.toGraph = function(element, options) {\n    const { neurons, connections } = this.toJSON();\n\n    // Flattens neuron layers from `Network.toJSON` and converts it to `vie-network`\n    // nodes\n    const nodes = new vis.DataSet(neurons.map(function(neuron) {\n      neuron.label = `${neuron.id}`;\n      neuron.color = neuron.type === \"input\" ? \"gray\" : neuron.type === \"output\" ? \"lime\" : \"orange\"; // \"input\" || \"output\" || \"hidden\"\n      return neuron;\n    }));\n    // Flattens connections from `Network.toJSON` and converts it into `vis-network`\n    // edges\n    const edges = new vis.DataSet(connections.map(function(connection) {\n      connection.arrows = \"to\";\n      return connection;\n    }));\n\n    // DOM id\n    if(typeof element === \"string\") element = document.getElementById(element);\n\n    // Vis.js Network Options\n    // Will have a \"left-to-right\" graph with \"smooth\" lines representing\n    // connections by default\n    options = options || {\n      edges: {\n        smooth: {\n          type: \"cubicBezier\",\n          forceDirection: \"horizontal\"\n        }\n      },\n      layout: {\n        hierarchical: {\n          direction: \"LR\",\n          sortMethod: \"directed\"\n        }\n      },\n      physics: false\n    }\n\n    return new vis.Network(element, { nodes, edges }, options);\n  }\n  //Code here...\n\n  //================================================\n  // END UTILITY FUNCTIONS =========================\n  //================================================\n}\n\nNetwork.networks = 0;\nNetwork.uid = function() {\n  return ++Network.networks;\n}\n\nNetwork.crossoverGenomes = function(genomeX, genomeY) {\n  const genome = genomeX;\n\n  // Compares and randomly chooses which connections from the different\n  // genomes to pass along to the offspring\n  genomeY.connections.forEach(function(connectionY) {\n    const index = genome.connections.findIndex(function(gene) {\n      return gene.id === connectionY.id;\n    });\n\n    // Did not have a match for GeneY in GeneX, therefor adding\n    // GeneY to the offspring. Also checks to see if the\n    // unknown connection has a neuron that is not in the genome\n    // yet - in which case, it is added to the genome.\n    if(index === -1) {\n      // Adds the disjointed or excess connection from genomeY to genomeX\n      genome.connections.push(connectionY);\n\n      console.log(`${connectionY.id} from: ${connectionY.from}`);\n      console.log(`${connectionY.id} to: ${connectionY.to}`);\n\n      // Adds the neurons from GenomeY to the offsprings genome if it doesn't\n      // exist already.\n      [connectionY.from, connectionY.to].forEach(function(neuronY) {\n        const index = genome.neurons.findIndex(function(neuron) {\n          return neuron.id === neuronY;\n        });\n\n        // Adds neuron from genome Y to the offsprings genome\n        if(index === -1) genome.neurons.push(genomeY.neurons.find(function(neuron) {\n          return neuron.id === neuronY;\n        }));\n\n        // We can add another selection method here.\n        // This just runs a random 50/50 chance selection.\n        // There's a 50/50 chance that the neuron will be picked from\n        // Genome Y or Genome X.\n        else genome.neurons[index] = Math.random() > 0.5 ? genome.neurons[index] : genomeY.neurons.find(function(neuron) {\n          return neuron.id === neuronY;\n        });\n      })\n    }\n    // There was a match for GeneY in GeneX, therefor randomly picking one\n    // to add to offspring\n    else {\n      // We can add another selection method here\n      // This just runs a random 50/50 chance selection\n      genome.connections[index] = Math.random() > 0.5 ? genome.connections[index] : connectionY;\n    }\n  })\n\n  return genome;\n  // const network = Network.fromGenome(genome);\n  // return network;\n}\n\n//================================================\n// CONSTRUCTORS ==================================\n//================================================\n\n/**\n* @param {number[]} sizes - Array of layer fromSizes\n*\n* @returns {Network}\n*\n* @example\n* const network = Network.fromSizes([20, 10, 3]);\n*/\nNetwork.fromSizes = function(sizes) {\n  const network = new Network();\n\n  // Create a series of Layers with the sizes given in `this.neurons`.\n  // `this.neurons = [[Neuron, Neuron, ...], [Neuron, Neuron, ...], ...]`\n  sizes.map(function(size, index) {\n    const neurons = [];\n    for(let n = 0; n < size; n++) {\n      const neuron = new Neuron();\n\n      // Here we set the last layer's neurons' type to \"output\"\n      // and the first layer's neurons' type to \"input\"\n      if(index === sizes.length - 1) neuron.type = \"output\";\n      else if(index === 0) neuron.type = \"input\";\n\n      neurons.push(neuron);\n    }\n    network.neurons.push(neurons);\n    return neurons;\n  })\n\n  // Connects the layers that we just created and stores the connections in\n  // `this.connections`\n  let previous = network.neurons[0];\n  network.neurons.slice(1, network.neurons.length).forEach(function(layer, index) {\n    for(let p = 0; p < previous.length; p++) {\n      for(let l = 0; l < layer.length; l++) {\n        network.connections.push(new Connection(previous[p], layer[l]));\n      }\n    }\n    previous = layer;\n  })\n\n  return network;\n}\n/**\n* Creates a network with the given shape (i.e. INPUTSxOUTPUTS). The created\n* network will not have any hidden neurons.\n*\n* @param {number} inputs - Size of the network's input layer\n* @param {number} outputs - Size of the network's output layer\n*\n* @returns {Network}\n*/\nNetwork.fromShape = function(inputs, outputs) {\n  const network = new Network();\n\n  // Create a network with no hidden layers, whose input layer is equal to\n  // `inputs` and whose output layer it equal to `outputs`\n  [inputs, outputs].map(function(size, index) {\n    const neurons = [];\n    for(let n = 0; n < size; n++) {\n      const neuron = new Neuron();\n\n      // Here we set the last layer's neurons' type to \"output\"\n      // and the first layer's neurons' type to \"input\"\n      if(index === 1) neuron.type = \"output\";\n      else if(index === 0) neuron.type = \"input\";\n\n      neurons.push(neuron);\n    }\n    network.neurons.push(neurons);\n    return neurons;\n  })\n\n  // Connects the layers that we just created and stores the connections in\n  // `this.connections`\n  let previous = network.neurons[0];\n  network.neurons.slice(1, network.neurons.length).forEach(function(layer, index) {\n    for(let p = 0; p < previous.length; p++) {\n      for(let l = 0; l < layer.length; l++) {\n        network.connections.push(new Connection(previous[p], layer[l]));\n      }\n    }\n    previous = layer;\n  });\n\n  return network;\n}\n/**\n* Creates a deep copy of the given genome\n*\n* @param {Genome} genome\n*\n* @returns {Network}\n*/\nNetwork.fromGenome = function(genome) {\n  const network = new Network();\n\n  // Creates a copy of neuron in the given network in the new network.\n  genome.neurons.forEach(function(neuron) {\n    network.neurons.push(new Neuron(neuron));\n  });\n\n  // Creates a deep copy of all the connections inthe given network into the new network.\n  // Even transpiles all the references in connections to refer to the new network.\n  genome.connections.forEach(function(connection) {\n    // Find the neurons in the new network that will create work to create\n    // the same endpoints as the given connection.\n    const from = network.neurons.find(function(neuron) {\n      return neuron.id === connection.from;\n    });\n    const to = network.neurons.find(function(neuron) {\n      return neuron.id === connection.to;\n    });\n\n    // Deep copies a new connection into the created network\n    network.connections.push(new Connection(from, to, connection.weight));\n  });\n\n  // Code here...\n\n  return network;\n}\n\n//================================================\n// END CONSTRUCTORS ==============================\n//================================================\n\n\n//================================================\n// TYPE DEFINITIONS ==============================\n//================================================\n\n\n//================================================\n// END TYPE DEFINITIONS ==========================\n//================================================\n\nmodule.exports = Network;\n\n\n//# sourceURL=webpack://NN/./src/network.js?");

/***/ }),

/***/ "./src/neuron.js":
/*!***********************!*\
  !*** ./src/neuron.js ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// const uid = require(\"cuid\");\nconst _ = __webpack_require__(/*! ./_ */ \"./src/_.js\");\nconst Connection = __webpack_require__(/*! ./connection */ \"./src/connection.js\");\n\n/**\n * Neurons are the engines that process and guide information though a neural\n * network. A neural networks \"intelligence\" is usually measured by the ability\n * for neurons to effectively process information as a group.\n *\n * ### What is a neuron?\n *\n * A _`Neuron`_ is a simplified mathematical model of a biological neuron.\n *\n * In people, a neuron is a cell that collects inputs from synapses (i.e. eyes,\n * ears, etc. or other neurons) and triggers an `output` signal when the\n * incoming signals pass a certain threshold.\n *\n * In biological neurons (in animals) or in artificial neurons (i.e. AI, NN,\n * Deep Learning, etc.), one neuron doesn’t do much, but when combined, neural\n * networks allow us to recognize the world around us, solve problems, and\n * interact with our environment.\n *\n * ### How do they work?\n *\n * Neural networks were inspired by the human brain, and like in a human brain\n * the basic building block is called a `Neuron`. Its functionality is similar\n * to a human neuron, i.e. it takes in some inputs and fires an output. In\n * purely mathematical terms, a neuron in the machine learning world is a\n * placeholder for a mathematical function, and its only job is to provide an\n * output by applying the function on the inputs provided.\n *\n * ![](https://miro.medium.com/max/805/1*XqXu-hBHocGoHh_65Rl8lQ.png)\n *\n * The function used in a neuron is generally called an _\"activation function\"_.\n * There have been 5 major activation functions tried to date, step, sigmoid,\n * tanh, and ReLU. For this neuron we are using a _\"sigmoid\"_ activation\n * function.\n *\n * ### What is a _\"sigmoid activation function\"_?\n *\n * A sigmoid function - or logistic function - is defined mathematically as:\n *\n * ![](https://miro.medium.com/max/460/1*MIeka59unAhS7MQk5e7FOg.png)\n *\n * The value of the function tends to zero when _**z**_ tends to negative\n * infinity and tends to 1 when _**z**_ tends to infinity. A sigmoid activation\n * function is an approximation of how a \"real neuron\" would behave; it's an\n * assumption in the field of deep learning.\n *\n * @constructs Neuron\n *\n * @param {Object} options\n * @param {number} [options.id]\n * @param {number} [options.bias]\n * @param {Object} options.optimizer\n * @param {number} options.optimizer.rate\n * @param {number} options.optimizer.momentum\n * @param {number} options.optimizer.decay\n * @param {number} options.optimizer.alpha\n * @param {number} options.optimizer.beta\n * @param {number} options.optimizer.gamma\n *\n *\n * @prop {string} id\n * @prop {number} bias\n * @prop {Object} optimizer\n * @prop {number} optimizer.rate\n * @prop {number} optimizer.momentum\n * @prop {number} optimizer.decay\n * @prop {number} optimizer.alpha\n * @prop {number} optimizer.beta\n * @prop {number} optimizer.gamma\n * @prop {Object} incoming\n * @prop {{ \"[ID]\": Neuron }} incoming.targets\n * @prop {{ \"[ID]\": number }} incoming.weights\n * @prop {Object} outgoing\n * @prop {{ \"[ID]\": Neuron }} outgoing.targets\n * @prop {{ \"[ID]\": number }} outgoing.weights\n * @prop {number} _output\n * @prop {number} output\n * @prop {number} error\n *\n * @example\n * //===============================================\n * // One Neuron (No Hidden Layers) ================\n * //===============================================\n * const { Neuron } = require(\"@liquidcarrot/nn\")\n *\n * const neuron = new Neuron();\n *\n * neuron.activate(0); // 0\n * neuron.propagate(1); // -1\n *\n * //===============================================\n * // Three Neurons (Hidden Layers) ================\n * //===============================================\n * const { Neuron } = require(\"@liquidcarrot/nn\")\n *\n * const input = new Neuron(); // Input Neuron (Layer)\n * const hidden = new Neuron(0.1); // Hidden Neuron (Layer)\n * const output = new Neuron(0.2); // Output Neuron (Layer)\n *\n * input.connect(hidden, 0.3); // Connects input layer to hidden layer\n * hidden.connect(output, 0.4); // Connects hidden layer to output layer\n *\n * input.activate(0); // 0\n * hidden.activate(); // 0.52497918747894\n * output.activate(); // 0.6010858826658407\n *\n * output.propagate(1); //  -0.09565228299910712\n * hidden.propagate(); // -0.009900697661026392\n * input.propagate(); // -0.0029702092983079176\n */\nfunction Neuron(neuron={}) {\n  this.id = neuron.id || Neuron.uid();\n\n  this.type = neuron.type == undefined ? \"hidden\" : neuron.type; // \"input\", \"hidden\", \"output\"\n  this.bias = neuron.bias == undefined ? Math.random() * 2 - 1 : neuron.bias;\n\n  this.connections = [];\n\n  // OPTIMIZERS\n  // CHECK: https://keras.io/optimizers/\n  // CHECK: http://ruder.io/optimizing-gradient-descent/index.html\n  // this._optimizer = Neuron.optimizers[Object.keys(Neuron.optimizers)[Math.floor(Object.keys(Neuron.optimizers).length * Math.random())];\n  this.optimizer = {}\n  this.optimizer.rate;\n  this.optimizer.momentum;\n  this.optimizer.decay;\n  this.optimizer.alpha;\n  this.optimizer.beta;\n  this.optimizer.gamma;\n\n  this.squash;\n  this.cost;\n\n\n  this.incoming = {\n    targets: {}, //new Map(),\n    weights: {}, //new Map(),\n    connections: {}\n  }\n  this.outgoing = {\n    targets: {}, // new Map(),\n    weights: {}, // new Map(),\n    connections: {}\n  }\n\n  this._output; // f'(x)\n  this.output; // f(x)\n  this.error; // E'(f(x))\n  this._error;// E(f(x))\n\n  //================================================\n  // CORE FUNCTIONS ================================\n  //================================================\n  /**\n   * @param {Neuron} neuron\n   * @param {number} [weight]\n   *\n   * @example\n   * const { Neuron } = require(\"@liquidcarrot/nn\")\n   *\n   * const neuron = new Neuron();\n   * const other = new Neuron();\n   *\n   * neuron.connect(other);\n   */\n  this.connect = function(neuron, weight) {\n    const connection = new Connection(this, neuron, weight);\n\n    this.outgoing.targets[neuron.id] = neuron;\n    this.outgoing.connections[neuron.id] = connection;\n\n    neuron.incoming.targets[this.id] = this;\n    neuron.incoming.connections[this.id] = connection;\n\n    this.outgoing.weights[neuron.id] = neuron.incoming.weights[this.id] = weight == undefined ? Math.random() * 2 - 1 : weight;\n    this.outgoing.connections[connection.id] = neuron.incoming.connections[connection.id] = connection;\n\n    return connection;\n  }\n\n  /**\n   * @param {number} [input]\n   *\n   * @returns {number} Returns the neuron's output\n   *\n   * @example\n   * //===============================================\n   * // One Neuron ===================================\n   * //===============================================\n   * const { Neuron } = require(\"@liquidcarrot/nn\")\n   *\n   * const neuron = new Neuron();\n   *\n   * neuron.activate(3);\n   *\n   * //===============================================\n   * // Two Neurons ==================================\n   * //===============================================\n   * const { Neuron } = require(\"@liquidcarrot/nn\")\n   *\n   * const neuron = new Neuron();\n   * const other = new Neuron(0.1);\n   *\n   * neuron.connect(other, 0.2);\n   *\n   * neuron.activate(3); // 3\n   * other.activate(); // 0.6681877721681662\n   */\n  this.activate = function(input) {\n    const self = this;\n\n    function sigmoid(x) { return 1 / (1 + Math.exp(-x)) } // f(x)\n    function _sigmoid(x) { return sigmoid(x) * (1 - sigmoid(x)) } // f'(x)\n\n    if(input != undefined) {\n      this._output = 1; // f'(x)\n      this.output = input; // f(x)\n    } else {\n      // Σ (x • w)\n      const sum = Object.keys(this.incoming.targets).reduce(function(total, target, index) {\n        return total += self.incoming.targets[target].output * self.incoming.weights[target];\n      }, this.bias);\n\n      this._output = _sigmoid(sum); // f'(x)\n      this.output = sigmoid(sum); // f(x)\n    }\n\n    return this.output;\n  }\n\n  /**\n   * @param {number} target\n   * @param {number} [rate=0.3]\n   *\n   * @return {number} Returns neuron's marginal error\n   *\n   * @example\n   * //===============================================\n   * // One Neuron ===================================\n   * //===============================================\n   * const { Neuron } = require(\"@liquidcarrot/nn\")\n   *\n   * const neuron = new Neuron();\n   *\n   * neuron.activate(3); // 3\n   * neuron.propagate(0); // 3\n   *\n   * //===============================================\n   * // Two Neurons ==================================\n   * //===============================================\n   * const { Neuron } = require(\"@liquidcarrot/nn\")\n   *\n   * const neuron = new Neuron();\n   * const other = new Neuron(0.1);\n   *\n   * neuron.connect(other, 0.2);\n   *\n   * neuron.activate(3); // 3\n   * other.activate(); // 0.6681877721681662\n   *\n   * other.propagate(0); // 0.14814583086672545\n   * neuron.propagate(); // 0.009876697690471913\n   */\n  this.propagate = function(target, rate=0.3) {\n    const self = this;\n\n    //𝛿E /𝛿squash\n    const sum = target == undefined ? Object.keys(this.outgoing.targets).reduce(function(total, target, index) {\n        // Δweight\n        self.outgoing.targets[target].incoming.weights[self.id] = self.outgoing.weights[target] -= rate * self.outgoing.targets[target].error * self.output;\n\n        return total += self.outgoing.targets[target].error * self.outgoing.weights[target];\n      }, 0) : this.output - target;\n\n    // 𝛿squash/𝛿sum\n    this.error = sum * this._output\n\n    // Δbias\n    this.bias -= rate * this.error;\n\n    return this.error;\n  }\n  //================================================\n  // END CORE FUNCTIONS ============================\n  //================================================\n\n  //================================================\n  // UTILITY FUNCTIONS =============================\n  //================================================\n\n  this.toJSON = function() {\n    return {\n      id: this.id,\n      bias: this.bias,\n      type: this.type\n    }\n  }\n\n  /**\n   * @param {boolean} [array=false] Iff `true`, will return an `Array` (`[[INCOMING_WEIGHTS], [OUTGOING_WEIGHTS]]`) - instead of a JSON Object (`{ incoming: [INCOMING_WEIGHTS], outgoing: [OUTGOING_WEIGHTS]`)\n   *\n   * @returns {Object|Array.<Array.<Number>>} Returns an `Array` or `Object` of incoming and outgoing weights\n   */\n  this.weights = function(options) {\n    options = options || {\n      json: true\n    }\n\n    if(options.json) return {\n      incoming: Object.values(this.incoming.weights),\n      outgoing: Object.values(this.outgoing.weights)\n    }\n    else return [Object.values(this.incoming.weights), Object.values(this.outgoing.weights)];\n  }\n\n\n  //Code here...\n\n  //================================================\n  // END UTILITY FUNCTIONS =========================\n  //================================================\n}\n\nNeuron.neurons = 0;\nNeuron.uid = function() {\n  return ++Neuron.neurons;\n}\nNeuron.activations = {\n  SIGMOID: function(x, dx) {\n    const fx = 1 / (1 + Math.exp(-x));\n\n    if(!dx) return _.clamp(fx);\n    else return _.clamp(fx * (1 - fx));\n  },\n  RELU: function(x, dx) {\n    if(x > 0) {\n      const fx = x;\n\n      return !dx ? _.clamp(x) : 1;\n    } else return 0;\n  },\n  TANH: function(x, dx) {\n    const fx = Math.tanh(x);\n\n    if(!dx) return _.clamp(fx);\n    else return _.clamp(1 - (fx * fx));\n  },\n  IDENTITY: function(x, dx) {\n    return !dx ? _.clamp(x) : 1;\n  },\n  STEP: function(x, dx) {\n    return x > 0 && dx ? 1 : 0;\n  }\n}\n\n\n/**\n* Optimizers are initiated with\n* { rate, momentum, decay, alpha, beta, epsilon, gamma }\n*/\nNeuron.optimizers = {\n  SGD: function() {},\n  NESTEROV: function() {},\n  RMSPROP: function() {},\n  ADAGRAD: function() {},\n  ADADELTA: function() {},\n  ADAM: function() {},\n  AMSGRAD: function() {},\n  ADAMAX: function() {},\n  NADAM: function() {}\n}\n\nmodule.exports = Neuron;\n\n\n//# sourceURL=webpack://NN/./src/neuron.js?");

/***/ })

/******/ });
});